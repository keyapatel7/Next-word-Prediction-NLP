Next-word-Prediction-NLP
ðŸ“Œ Project Overview

This project implements a Next Word Prediction system using Natural Language Processing (NLP) and Bidirectional LSTM (BiLSTM).
The model predicts the most likely next word based on a given sequence of input words.

Next-word prediction is widely used in:

Search engines

Chatbots

Text auto-completion

Language modeling applications

ðŸ§  Model Architecture

The model is built using TensorFlow/Keras with the following architecture:

Input Layer (15 words)
â†“
Embedding Layer (100 dimensions)
â†“
Bidirectional LSTM
â†“
Dropout
â†“
Bidirectional LSTM
â†“
Dropout
â†“
Dense Layer (Softmax Output)

ðŸ“Š Model Summary
Layer	Output Shape	Parameters
Embedding	(None, 15, 100)	275,100
BiLSTM	(None, 15, 300)	301,200
BiLSTM	(None, 300)	541,200
Dense	(None, 2751)	828,051
Total Parameters		1,945,551
ðŸ“‚ Dataset

Text-based dataset

Tokenized and padded to a fixed length of 15 words

Vocabulary size: 2,751 words

Converted into inputâ€“output word sequences for training



ðŸ§ª Sample Prediction

Input:

"Machine learning is"


Predicted Output:

"the"
